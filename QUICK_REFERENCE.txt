╔════════════════════════════════════════════════════════════════════════════════╗
║                                                                                ║
║                    🚀 Fashion MNIST 增量训练 - 快速参考卡                          ║
║                                                                                ║
╚════════════════════════════════════════════════════════════════════════════════╝

┌─ 最常用的命令 ─────────────────────────────────────────────────────────────────┐
│                                                                                 │
│  推荐命令（一行代码，开始微调）：                                               │
│                                                                                 │
│  cd FashionMNIST/mnist/src && python finetune-gpu.py \                         │
│    --model-path=../../../model/mnist_cnn3.pt                                   │
│                                                                                 │
│  或者（使用shell脚本）：                                                        │
│                                                                                 │
│  bash run_finetune.sh 1                                                        │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘

┌─ 四种方案一览 ─────────────────────────────────────────────────────────────────┐
│                                                                                 │
│  【方案1】轻度微调 - 最安全 ⭐ 推荐首选                                          │
│  $ bash run_finetune.sh 1                                                      │
│  学习率: 0.001  |  Batch: 256  |  Epochs: 30  |  冻结卷积: ❌                  │
│  预计改进: 0.5-1%  |  训练时间: ~25分钟                                         │
│                                                                                 │
│  【方案2】头部微调 - 只训练FC层（数据少时）                                      │
│  $ bash run_finetune.sh 2                                                      │
│  学习率: 0.001  |  Batch: 256  |  Epochs: 30  |  冻结卷积: ✅                  │
│  预计改进: 0.2-0.5%  |  训练时间: ~25分钟                                       │
│                                                                                 │
│  【方案3】深度微调 - 需要大幅改进                                               │
│  $ bash run_finetune.sh 3                                                      │
│  学习率: 0.002  |  Batch: 512  |  Epochs: 50  |  冻结卷积: ❌                  │
│  预计改进: 1-2%  |  训练时间: ~50分钟                                          │
│                                                                                 │
│  【方案4】保守微调 - 非常谨慎                                                   │
│  $ bash run_finetune.sh 4                                                      │
│  学习率: 0.0005  |  Batch: 256  |  Epochs: 30  |  冻结卷积: ❌                 │
│  预计改进: 0.2-0.8%  |  训练时间: ~25分钟                                       │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘

┌─ 自定义命令 ───────────────────────────────────────────────────────────────────┐
│                                                                                 │
│  cd FashionMNIST/mnist/src                                                     │
│  python finetune-gpu.py \                                                      │
│    --model-path=../../../model/mnist_cnn3.pt \  # 模型路径（必需）              │
│    --batch-size=256 \                           # 批次大小                      │
│    --lr=0.001 \                                 # 学习率                        │
│    --epochs=30 \                                # 训练轮数                      │
│    --scheduler=cosine \                         # 学习率调度                    │
│    --freeze-conv                                # 冻结卷积层（可选）            │
│                                                                                 │
│  关键参数：                                                                     │
│  --batch-size      : 256, 512 (推荐)                                           │
│  --lr               : 0.001, 0.002, 0.0005                                     │
│  --epochs           : 20-100                                                   │
│  --scheduler        : cosine, plateau, none                                    │
│  --freeze-conv      : 冻结卷积层（只训练FC）                                    │
│  --freeze-bn        : 冻结BatchNorm                                            │
│  --dropout          : Dropout率 (默认0.3)                                      │
│  --min-lr           : 最小学习率 (默认1e-5)                                     │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘

┌─ 监控和查看 ───────────────────────────────────────────────────────────────────┐
│                                                                                 │
│  启动 TensorBoard：                                                             │
│  $ tensorboard --logdir=logs_finetune                                          │
│                                                                                 │
│  然后打开浏览器：http://localhost:6006                                         │
│                                                                                 │
│  查看准确率、损失、学习率等实时曲线                                             │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘

┌─ 文件位置 ─────────────────────────────────────────────────────────────────────┐
│                                                                                 │
│  脚本位置：                                                                     │
│    finetune-gpu.py  →  FashionMNIST/mnist/src/                                │
│    test-model.py    →  FashionMNIST/mnist/src/                                │
│                                                                                 │
│  文档位置：                                                                     │
│    FINETUNE_GUIDE.md  →  详细使用指南                                          │
│    INCREMENTAL_TRAINING_SUMMARY.md  →  方案总结                               │
│    FILES_CREATED.md  →  完整清单                                              │
│                                                                                 │
│  模型位置：                                                                     │
│    输入：model/mnist_cnn3.pt                                                   │
│    输出：FashionMNIST/mnist/data/mnt/mnist_cnn_finetuned.pt                   │
│    日志：FashionMNIST/mnist/src/logs_finetune/                                │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘

┌─ 快速诊断 ─────────────────────────────────────────────────────────────────────┐
│                                                                                 │
│  测试模型是否正常加载：                                                         │
│  $ cd FashionMNIST/mnist/src                                                   │
│  $ python test-model.py --model-path=../../../model/mnist_cnn3.pt             │
│                                                                                 │
│  预期输出：✅ 所有测试通过！模型可以进行微调训练                                │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘

┌─ 常见问题速答 ─────────────────────────────────────────────────────────────────┐
│                                                                                 │
│  Q: 精度反而下降？                                                              │
│  A: 降低学习率 or 减少epochs or 使用 --freeze-conv                             │
│                                                                                 │
│  Q: 显存溢出？                                                                  │
│  A: 减少 --batch-size (512→256) or 使用 --freeze-conv                        │
│                                                                                 │
│  Q: 训练很慢？                                                                  │
│  A: 增加 --batch-size (256→512) 会加快训练                                    │
│                                                                                 │
│  Q: 如何继续微调已微调的模型？                                                  │
│  A: python finetune-gpu.py \                                                   │
│       --model-path=../data/mnt/mnist_cnn_finetuned.pt \                       │
│       --lr=0.0005 --epochs=20                                                 │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘

┌─ 预期性能 ─────────────────────────────────────────────────────────────────────┐
│                                                                                 │
│  当前模型：91% accuracy                                                       │
│                                                                                 │
│  微调预期：                                                                     │
│    方案1 (轻微调)    : 91.0% → 91.5-92.0% ✅                                  │
│    方案2 (头部微调)  : 91.0% → 91.2-91.5% ✅                                  │
│    方案3 (深度微调)  : 91.0% → 92.0-93.0% ✅                                  │
│    多轮微调         : 91.0% → 93.0-94.0% (需要多次实验)                      │
│                                                                                 │
│  注：从91%→95%非常困难，可能需要架构改进（如ResNet）                           │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘

┌─ 使用流程 ─────────────────────────────────────────────────────────────────────┐
│                                                                                 │
│  1️⃣  测试模型：                                                                 │
│      python test-model.py --model-path=../../../model/mnist_cnn3.pt            │
│                                                                                 │
│  2️⃣  选择方案执行：                                                              │
│      bash run_finetune.sh 1  (推荐)                                           │
│                                                                                 │
│  3️⃣  监控进度：                                                                  │
│      tensorboard --logdir=logs_finetune                                        │
│      浏览器打开: http://localhost:6006                                         │
│                                                                                 │
│  4️⃣  保存模型（自动完成）：                                                       │
│      FashionMNIST/mnist/data/mnt/mnist_cnn_finetuned.pt                       │
│                                                                                 │
│  5️⃣  可选：继续微调或尝试其他方案                                               │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘

╔════════════════════════════════════════════════════════════════════════════════╗
║                                                                                ║
║  📚 详细文档请查看：FINETUNE_GUIDE.md 或 INCREMENTAL_TRAINING_SUMMARY.md       ║
║                                                                                ║
║  🎯 现在就开始：bash run_finetune.sh 1                                          ║
║                                                                                ║
╚════════════════════════════════════════════════════════════════════════════════╝
