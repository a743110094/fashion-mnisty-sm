#!/bin/bash

# å¢é‡è®­ç»ƒæ‰§è¡Œè„šæœ¬
# ä½¿ç”¨æ–¹æ³•: bash run_finetune.sh [æ–¹æ¡ˆå·]
# ä¾‹å¦‚: bash run_finetune.sh 1

set -e  # å‡ºé”™æ—¶åœæ­¢

cd "$(dirname "$0")"
cd FashionMNIST/mnist/src

PLAN=${1:-1}  # é»˜è®¤æ–¹æ¡ˆ1

echo "======================================"
echo "ğŸš€ Fashion MNIST å¢é‡è®­ç»ƒ"
echo "======================================"
echo ""

case $PLAN in
    1)
        echo "ğŸ“‹ æ–¹æ¡ˆ1: è½»åº¦å¾®è°ƒï¼ˆæ¨èé¦–é€‰ï¼‰"
        echo "å­¦ä¹ ç‡: 0.001"
        echo "Batch Size: 256"
        echo "Epochs: 30"
        echo "Scheduler: Cosine"
        echo ""
        python finetune-gpu.py \
            --model-path=../../../model/mnist_cnn3.pt \
            --batch-size=256 \
            --lr=0.001 \
            --epochs=30 \
            --scheduler=cosine
        ;;
    2)
        echo "ğŸ“‹ æ–¹æ¡ˆ2: å¤´éƒ¨å¾®è°ƒï¼ˆåªè®­ç»ƒFCå±‚ï¼‰"
        echo "å­¦ä¹ ç‡: 0.001"
        echo "Batch Size: 256"
        echo "Epochs: 30"
        echo "å†»ç»“: å·ç§¯å±‚"
        echo ""
        python finetune-gpu.py \
            --model-path=../../../model/mnist_cnn3.pt \
            --batch-size=256 \
            --lr=0.001 \
            --epochs=30 \
            --freeze-conv \
            --scheduler=cosine
        ;;
    3)
        echo "ğŸ“‹ æ–¹æ¡ˆ3: æ·±åº¦å¾®è°ƒï¼ˆæ›´æ¿€è¿›ï¼‰"
        echo "å­¦ä¹ ç‡: 0.002"
        echo "Batch Size: 512"
        echo "Epochs: 50"
        echo "Scheduler: Cosine"
        echo ""
        python finetune-gpu.py \
            --model-path=../../../model/mnist_cnn3.pt \
            --batch-size=512 \
            --lr=0.002 \
            --epochs=50 \
            --scheduler=cosine \
            --min-lr=0.00005
        ;;
    4)
        echo "ğŸ“‹ æ–¹æ¡ˆ4: ä¿å®ˆå¾®è°ƒï¼ˆå°å¿ƒç¿¼ç¿¼ï¼‰"
        echo "å­¦ä¹ ç‡: 0.0005"
        echo "Batch Size: 256"
        echo "Epochs: 30"
        echo "Dropout: 0.2"
        echo ""
        python finetune-gpu.py \
            --model-path=../../../model/mnist_cnn3.pt \
            --batch-size=256 \
            --lr=0.0005 \
            --epochs=30 \
            --scheduler=cosine \
            --min-lr=0.00001 \
            --dropout=0.2
        ;;
    test)
        echo "ğŸ“‹ æµ‹è¯•æ¨¡å‹åŠ è½½"
        python test-model.py --model-path=../../../model/mnist_cnn3.pt
        ;;
    *)
        echo "âŒ æœªçŸ¥çš„æ–¹æ¡ˆ: $PLAN"
        echo ""
        echo "å¯ç”¨æ–¹æ¡ˆ:"
        echo "  1 - è½»åº¦å¾®è°ƒï¼ˆæ¨èï¼‰"
        echo "  2 - å¤´éƒ¨å¾®è°ƒï¼ˆåªè®­ç»ƒFCå±‚ï¼‰"
        echo "  3 - æ·±åº¦å¾®è°ƒï¼ˆæ›´æ¿€è¿›ï¼‰"
        echo "  4 - ä¿å®ˆå¾®è°ƒï¼ˆå°å¿ƒç¿¼ç¿¼ï¼‰"
        echo "  test - æµ‹è¯•æ¨¡å‹åŠ è½½"
        echo ""
        echo "ä½¿ç”¨æ–¹æ³•: bash run_finetune.sh [æ–¹æ¡ˆå·]"
        exit 1
        ;;
esac

echo ""
echo "======================================"
echo "âœ… è®­ç»ƒå®Œæˆï¼"
echo "======================================"
echo ""
echo "ğŸ’¡ æŸ¥çœ‹ç»“æœ:"
echo "  tensorboard --logdir=logs_finetune"
echo ""
echo "ğŸ“ æ¨¡å‹ä¿å­˜ä½ç½®:"
echo "  ../data/mnt/mnist_cnn_finetuned.pt"
echo ""
