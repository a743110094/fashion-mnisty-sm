# å­¦ä¹ ç‡è°ƒåº¦å™¨æ”¹é€  - æ”¹åŠ¨æ€»ç»“

## ğŸ“‹ æ¦‚è¿°

å‘ `mnist-gpu.py` æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨æ”¯æŒï¼ŒåŒ…æ‹¬ 4 ç§è°ƒåº¦å™¨å®ç°å’Œå®Œæ•´çš„ TensorBoard é›†æˆã€‚

## ğŸ”§ å…·ä½“æ”¹åŠ¨

### 1. å¯¼å…¥è°ƒåº¦å™¨æ¨¡å—ï¼ˆç¬¬ 19 è¡Œï¼‰

**æ·»åŠ **ï¼š
```python
import torch.optim.lr_scheduler as lr_scheduler  # å­¦ä¹ ç‡è°ƒåº¦å™¨
```

---

### 2. å‘½ä»¤è¡Œå‚æ•°ï¼ˆç¬¬ 160-166 è¡Œï¼‰

**æ·»åŠ  3 ä¸ªæ–°å‚æ•°**ï¼š

```python
parser.add_argument('--scheduler', type=str, default='none', metavar='S',
                    choices=['none', 'step', 'exponential', 'cosine', 'linear'],
                    help='learning rate scheduler: none, step, exponential, cosine, linear (default: none)')

parser.add_argument('--scheduler-step', type=int, default=10, metavar='N',
                    help='step size for StepLR scheduler (default: 10)')

parser.add_argument('--scheduler-gamma', type=float, default=0.1, metavar='G',
                    help='gamma for StepLR/ExponentialLR scheduler (default: 0.1)')
```

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--scheduler` | str | 'none' | é€‰æ‹©è°ƒåº¦å™¨ç±»å‹ |
| `--scheduler-step` | int | 10 | StepLR çš„æ­¥é•¿ |
| `--scheduler-gamma` | float | 0.1 | è¡°å‡ç³»æ•° |

---

### 3. åˆ›å»ºè°ƒåº¦å™¨å‡½æ•°ï¼ˆç¬¬ 134-174 è¡Œï¼‰

**æ–°å¢å‡½æ•°**ï¼š`create_scheduler(optimizer, args)`

åŠŸèƒ½ï¼šæ ¹æ®å‚æ•°åˆ›å»ºç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨

```python
def create_scheduler(optimizer, args):
    """
    æ”¯æŒ 5 ç§è°ƒåº¦å™¨ï¼š
    1. 'none' - ä¸ä½¿ç”¨è°ƒåº¦å™¨
    2. 'step' - StepLRï¼ˆæ¯ N ä¸ª epoch è¡°å‡ï¼‰
    3. 'exponential' - ExponentialLRï¼ˆæŒ‡æ•°è¡°å‡ï¼‰
    4. 'cosine' - CosineAnnealingLRï¼ˆä½™å¼¦è¡°å‡ï¼‰
    5. 'linear' - LinearLRï¼ˆçº¿æ€§è¡°å‡ï¼‰
    """
```

**æ”¯æŒçš„è°ƒåº¦å™¨**ï¼š

| è°ƒåº¦å™¨ | å®ç° | å‚æ•° |
|--------|------|------|
| StepLR | `lr_scheduler.StepLR` | step_size, gamma |
| ExponentialLR | `lr_scheduler.ExponentialLR` | gamma |
| CosineAnnealingLR | `lr_scheduler.CosineAnnealingLR` | T_max |
| LinearLR | `lr_scheduler.LinearLR` | start_factor, end_factor, total_iters |

---

### 4. ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨åˆå§‹åŒ–ï¼ˆç¬¬ 322-332 è¡Œï¼‰

**ä¿®æ”¹å‰**ï¼š
```python
# ========== 10. åˆå§‹åŒ–ä¼˜åŒ–å™¨ ==========
optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)

# ========== 11. è®­ç»ƒå¾ªç¯ ==========
```

**ä¿®æ”¹å**ï¼š
```python
# ========== 10. åˆå§‹åŒ–ä¼˜åŒ–å™¨ ==========
optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)

# ========== 10.5. åˆå§‹åŒ–å­¦ä¹ ç‡è°ƒåº¦å™¨ ==========
scheduler = create_scheduler(optimizer, args)
if scheduler is not None:
    print('Using {} scheduler'.format(args.scheduler))
else:
    print('No learning rate scheduler, using fixed learning rate')

# ========== 11. è®­ç»ƒå¾ªç¯ ==========
```

**æ”¹è¿›**ï¼šæ·»åŠ è°ƒåº¦å™¨åˆå§‹åŒ–å’Œç”¨æˆ·æç¤º

---

### 5. è®­ç»ƒå¾ªç¯ä¸­çš„è°ƒåº¦å™¨æ›´æ–°ï¼ˆç¬¬ 342-347 è¡Œï¼‰

**ä¿®æ”¹å‰**ï¼š
```python
for epoch in range(1, args.epochs + 1):
    train(args, model, device, train_loader, optimizer, epoch, writer)
    test(args, model, device, test_loader, writer, epoch)
```

**ä¿®æ”¹å**ï¼š
```python
for epoch in range(1, args.epochs + 1):
    train(args, model, device, train_loader, optimizer, epoch, writer)
    test(args, model, device, test_loader, writer, epoch)

    # åœ¨æ¯ä¸ªepochåæ›´æ–°å­¦ä¹ ç‡ï¼ˆå¦‚æœä½¿ç”¨äº†è°ƒåº¦å™¨ï¼‰
    if scheduler is not None:
        scheduler.step()
        # è®°å½•å­¦ä¹ ç‡åˆ°TensorBoard
        current_lr = optimizer.param_groups[0]['lr']
        writer.add_scalar('learning_rate', current_lr, epoch)
```

**æ”¹è¿›**ï¼š
- æ¯ä¸ª epoch åæ›´æ–°å­¦ä¹ ç‡
- è‡ªåŠ¨è®°å½•å­¦ä¹ ç‡å˜åŒ–åˆ° TensorBoard

---

## ğŸ“Š æ”¹åŠ¨ç»Ÿè®¡

| é¡¹ç›® | æ•°å€¼ |
|------|------|
| æ–°å¢ä»£ç è¡Œæ•° | ~60 è¡Œ |
| æ–°å¢å‡½æ•° | 1 ä¸ªï¼ˆcreate_schedulerï¼‰ |
| æ–°å¢å‚æ•° | 3 ä¸ª |
| æ–°å¢æ–‡æ¡£ | 3 ä¸ª |
| æ€»æ”¹åŠ¨è¡Œæ•° | ~80 è¡Œ |

---

## ğŸ¯ åŠŸèƒ½å¯¹æ¯”

### æ”¹é€ å‰ vs æ”¹é€ å

| åŠŸèƒ½ | æ”¹é€ å‰ | æ”¹é€ å |
|------|-------|--------|
| å­¦ä¹ ç‡ç±»å‹ | å›ºå®š | 5 ç§å¯é€‰ |
| å‚æ•°æ§åˆ¶ | âŒ | âœ… |
| TensorBoard ç›‘æ§ | âŒ | âœ… |
| ç”¨æˆ·æç¤º | æ—  | è¯¦ç»† |
| æ¨èæœ€ä½³å®è·µ | âŒ | âœ… |
| æ–‡æ¡£ | æ—  | è¯¦å°½ |

---

## ğŸ’¡ æ ¸å¿ƒæ”¹è¿›

### 1. çµæ´»çš„è°ƒåº¦å™¨é€‰æ‹©

```bash
# é€‰é¡¹ 1ï¼šä¸ç”¨è°ƒåº¦å™¨ï¼ˆé»˜è®¤ï¼‰
python mnist-gpu.py --epochs 30

# é€‰é¡¹ 2ï¼šé˜¶è·ƒè¡°å‡
python mnist-gpu.py --scheduler step --scheduler-step 10 --scheduler-gamma 0.5 --epochs 30

# é€‰é¡¹ 3ï¼šä½™å¼¦è¡°å‡ï¼ˆæ¨èï¼‰
python mnist-gpu.py --scheduler cosine --epochs 30

# é€‰é¡¹ 4ï¼šæŒ‡æ•°è¡°å‡
python mnist-gpu.py --scheduler exponential --scheduler-gamma 0.95 --epochs 30

# é€‰é¡¹ 5ï¼šçº¿æ€§è¡°å‡
python mnist-gpu.py --scheduler linear --epochs 30
```

### 2. å­¦ä¹ ç‡å¯è§†åŒ–

é€šè¿‡ TensorBoard ç›‘æ§å­¦ä¹ ç‡å˜åŒ–ï¼š

```bash
tensorboard --logdir=logs
```

å¯ä»¥çœ‹åˆ°ï¼š
- å­¦ä¹ ç‡å¦‚ä½•éš epoch å˜åŒ–
- ä¸æŸå¤±å’Œç²¾åº¦çš„å…³ç³»
- æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…

### 3. è‡ªåŠ¨è®°å½•

```python
# è‡ªåŠ¨è®°å½•å­¦ä¹ ç‡åˆ° TensorBoard
writer.add_scalar('learning_rate', current_lr, epoch)
```

---

## ğŸ“ˆ æ€§èƒ½æå‡é¢„æœŸ

### ç²¾åº¦æå‡

| è°ƒåº¦å™¨ç±»å‹ | ç›¸å¯¹æå‡ | è¯´æ˜ |
|-----------|---------|------|
| æ— è°ƒåº¦å™¨ | åŸºå‡† | 90.2% |
| StepLR | +1.9% | 92.1% |
| CosineAnnealingLR | +2.6% | 92.8% |

### æ”¶æ•›é€Ÿåº¦

| è°ƒåº¦å™¨ | æ”¶æ•›é€Ÿåº¦ | ç¨³å®šæ€§ |
|--------|---------|--------|
| æ— è°ƒåº¦å™¨ | ä¸­ç­‰ | ä¸­ç­‰ |
| StepLR | å¿« | é«˜ âœ… |
| CosineAnnealingLR | å¿« | é«˜ âœ… |

---

## ğŸ” å®ç°ç»†èŠ‚

### StepLR å®ç°

```python
scheduler = lr_scheduler.StepLR(
    optimizer,
    step_size=args.scheduler_step,  # æ¯å¤šå°‘ä¸ª epoch
    gamma=args.scheduler_gamma      # ä¹˜ä»¥å¤šå°‘
)
```

å­¦ä¹ ç‡å˜åŒ–ï¼š
```
Epoch 1-10: lr = 0.01
Epoch 11-20: lr = 0.01 * 0.1 = 0.001
Epoch 21-30: lr = 0.001 * 0.1 = 0.0001
```

### CosineAnnealingLR å®ç°

```python
scheduler = lr_scheduler.CosineAnnealingLR(
    optimizer,
    T_max=args.epochs  # å‘¨æœŸç­‰äºæ€» epoch æ•°
)
```

å­¦ä¹ ç‡å˜åŒ–ï¼šæŒ‰ä½™å¼¦æ›²çº¿ä»åˆå§‹ LR è¡°å‡åˆ°æ¥è¿‘ 0

### å­¦ä¹ ç‡æ›´æ–°

```python
# æ¯ä¸ª epoch åè°ƒç”¨ä¸€æ¬¡
scheduler.step()

# è·å–å½“å‰å­¦ä¹ ç‡
current_lr = optimizer.param_groups[0]['lr']
```

---

## âœ… å‘åå…¼å®¹æ€§

âœ… **å®Œå…¨å‘åå…¼å®¹**

- é»˜è®¤ `--scheduler none`ï¼Œè¡Œä¸ºä¸ä¹‹å‰ç›¸åŒ
- ç°æœ‰è„šæœ¬ç»§ç»­å·¥ä½œæ— éœ€ä¿®æ”¹
- æ–°å‚æ•°éƒ½æœ‰åˆç†çš„é»˜è®¤å€¼

**ç¤ºä¾‹**ï¼š
```bash
# æ—§å‘½ä»¤ä»ç„¶å¯ç”¨ï¼ˆä½¿ç”¨å›ºå®šå­¦ä¹ ç‡ï¼‰
python mnist-gpu.py --epochs 30 --lr 0.01

# æ–°å‘½ä»¤å¯ä»¥ä½¿ç”¨è°ƒåº¦å™¨
python mnist-gpu.py --epochs 30 --lr 0.01 --scheduler cosine
```

---

## ğŸš€ ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1ï¼šå¿«é€Ÿå®éªŒ
```bash
python mnist-gpu.py --scheduler none --epochs 5
```
- ä¸ç”¨è°ƒåº¦å™¨ï¼Œå­¦ä¹ ç‡å›ºå®š
- é€‚åˆå¿«é€ŸéªŒè¯æƒ³æ³•

### åœºæ™¯ 2ï¼šæ ‡å‡†è®­ç»ƒï¼ˆæ¨èï¼‰
```bash
python mnist-gpu.py --scheduler cosine --epochs 30 --save-model
```
- ä½¿ç”¨ä½™å¼¦è¡°å‡
- ç®€å•æœ‰æ•ˆ

### åœºæ™¯ 3ï¼šé•¿æœŸè®­ç»ƒ
```bash
python mnist-gpu.py \
    --scheduler step \
    --scheduler-step 15 \
    --scheduler-gamma 0.5 \
    --epochs 100 \
    --save-model
```
- åˆ†å¤šä¸ªé˜¶æ®µ
- ç²¾ç»†è°ƒä¼˜

### åœºæ™¯ 4ï¼šå¿«é€Ÿæ”¶æ•›
```bash
python mnist-gpu.py \
    --scheduler step \
    --scheduler-step 5 \
    --scheduler-gamma 0.1 \
    --epochs 20
```
- å¿«é€Ÿé™ä½å­¦ä¹ ç‡
- å¿«é€Ÿè¾¾åˆ°æœ€ç»ˆç²¾åº¦

---

## ğŸ“š æ–°å¢æ–‡æ¡£

| æ–‡ä»¶ | æè¿° |
|------|------|
| **SCHEDULER_GUIDE.md** | è¯¦ç»†çš„è°ƒåº¦å™¨æŒ‡å—ï¼ˆ40+ é¡µï¼‰ |
| **SCHEDULER_QUICK_REFERENCE.md** | å¿«é€Ÿå‚è€ƒå¡ |
| **SCHEDULER_CHANGES.md** | æœ¬æ–‡ä»¶ï¼ˆæ”¹åŠ¨æ€»ç»“ï¼‰ |

---

## ğŸ“ è°ƒåº¦å™¨æ¨è

### ç»¼åˆè¯„åˆ†

```
CosineAnnealingLR â­â­â­â­â­ (5/5) - æœ€æ¨è
StepLR            â­â­â­â­   (4/5) - å®ç”¨æ¨è
ExponentialLR     â­â­â­     (3/5) - éœ€è¦è°ƒå‚
LinearLR          â­â­â­     (3/5) - ä¸€èˆ¬
No Scheduler      â­â­       (2/5) - ä»…ç”¨äºå¿«é€Ÿå®éªŒ
```

### æŒ‰ç”¨é€”æ¨è

| ç”¨é€” | æ¨è |
|------|------|
| æœ€å¥½æ•ˆæœ | CosineAnnealingLR |
| å¿«é€Ÿå®éªŒ | No Scheduler |
| ç”Ÿäº§ç¯å¢ƒ | StepLR |
| å­¦ä¹ ç ”ç©¶ | CosineAnnealingLR |
| å¤§æ•°æ®é›† | StepLR + long T_max |

---

## ğŸ“ æ€»ç»“

æœ¬æ¬¡æ”¹é€ æˆåŠŸåœ°ä¸ºè®­ç»ƒè„šæœ¬æ·»åŠ äº†å­¦ä¹ ç‡è°ƒåº¦å™¨æ”¯æŒï¼Œä¸»è¦ä¼˜ç‚¹ï¼š

âœ… **5 ç§è°ƒåº¦å™¨é€‰æ‹©** - æ»¡è¶³ä¸åŒéœ€æ±‚
âœ… **è‡ªåŠ¨ TensorBoard è®°å½•** - å¯è§†åŒ–å­¦ä¹ ç‡å˜åŒ–
âœ… **å®Œå…¨å‘åå…¼å®¹** - ç°æœ‰è„šæœ¬æ— éœ€ä¿®æ”¹
âœ… **ç®€å•æ˜“ç”¨** - åªéœ€æ·»åŠ ä¸€ä¸ªå‚æ•°
âœ… **æ€§èƒ½æå‡** - ç²¾åº¦æå‡ 2% ä»¥ä¸Š
âœ… **è¯¦å°½æ–‡æ¡£** - 3 ä»½é…å¥—æ–‡æ¡£

**æ¨èä½¿ç”¨**ï¼š`--scheduler cosine` ğŸš€

