"""
æ¨¡å‹æµ‹è¯•è„šæœ¬ - å¿«é€ŸéªŒè¯æ¨¡å‹æ˜¯å¦å¯æ­£å¸¸åŠ è½½å’Œè¿è¡Œ
"""

import argparse
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms


class Net(nn.Module):
    def __init__(self, dropout_rate=0.3):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2)
        self.bn1 = nn.BatchNorm2d(64)

        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(128)

        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm2d(256)

        self.dropout2d = nn.Dropout2d(p=dropout_rate)
        self.gap = nn.AdaptiveAvgPool2d((1, 1))

        self.fc1 = nn.Linear(256, 256)
        self.bn_fc = nn.BatchNorm1d(256)
        self.dropout = nn.Dropout(p=dropout_rate)
        self.fc2 = nn.Linear(256, 10)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.max_pool2d(x, 2, 2)

        x = F.relu(self.bn2(self.conv2(x)))
        x = F.max_pool2d(x, 2, 2)

        x = F.relu(self.bn3(self.conv3(x)))
        x = F.max_pool2d(x, 2, 2)

        x = self.gap(x)
        x = x.view(x.size(0), -1)

        x = self.fc1(x)
        x = self.bn_fc(x)
        x = F.relu(x)
        x = self.dropout(x)

        x = self.fc2(x)
        return F.log_softmax(x, dim=1)


def test_model(model_path, device='cuda'):
    """
    æµ‹è¯•æ¨¡å‹ï¼šéªŒè¯æ¨¡å‹åŠ è½½ã€å‰å‘ä¼ æ’­ã€è¯„ä¼°ç­‰åŠŸèƒ½
    """
    print("=" * 60)
    print("ğŸ§ª æ¨¡å‹æµ‹è¯•è„šæœ¬")
    print("=" * 60)

    # 1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    print(f"\n1ï¸âƒ£  æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False

    file_size = os.path.getsize(model_path) / 1024 / 1024
    print(f"âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨: {model_path}")
    print(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} MB")

    # 2. æ£€æŸ¥GPUå¯ç”¨æ€§
    print(f"\n2ï¸âƒ£  æ£€æŸ¥è®¡ç®—è®¾å¤‡...")
    if device == 'cuda':
        if not torch.cuda.is_available():
            print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
            device = 'cpu'
        else:
            print(f"âœ… CUDAå¯ç”¨")
            print(f"   GPUå‹å·: {torch.cuda.get_device_name(0)}")
            print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024 / 1024 / 1024:.1f} GB")
    else:
        print(f"âœ… ä½¿ç”¨CPUæ¨¡å¼")

    device = torch.device(device)

    # 3. åˆ›å»ºæ¨¡å‹
    print(f"\n3ï¸âƒ£  åˆ›å»ºæ¨¡å‹æ¶æ„...")
    model = Net(dropout_rate=0.3).to(device)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"   æ€»å‚æ•°æ•°: {total_params:,}")

    # 4. åŠ è½½é¢„è®­ç»ƒæƒé‡
    print(f"\n4ï¸âƒ£  åŠ è½½é¢„è®­ç»ƒæƒé‡...")
    try:
        checkpoint = torch.load(model_path, map_location=device)
        model.load_state_dict(checkpoint)
        print(f"âœ… æƒé‡åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return False

    # 5. æµ‹è¯•å‰å‘ä¼ æ’­
    print(f"\n5ï¸âƒ£  æµ‹è¯•å‰å‘ä¼ æ’­...")
    model.eval()
    try:
        with torch.no_grad():
            dummy_input = torch.randn(1, 1, 28, 28).to(device)
            output = model(dummy_input)
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   è¾“å…¥å½¢çŠ¶: {dummy_input.shape}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"   è¾“å‡ºå€¼ (logits): {output[0]}")
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        return False

    # 6. æµ‹è¯•è¯„ä¼°æ¨¡å¼
    print(f"\n6ï¸âƒ£  åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°...")
    try:
        # åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆåªç”¨å‰100ä¸ªæ ·æœ¬ä»¥åŠ å¿«é€Ÿåº¦ï¼‰
        test_loader = torch.utils.data.DataLoader(
            datasets.FashionMNIST('../data', train=False, transform=transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])),
            batch_size=32, shuffle=False, num_workers=2
        )

        correct = 0
        total = 0
        losses = []

        with torch.no_grad():
            for i, (data, target) in enumerate(test_loader):
                if i >= 3:  # åªæµ‹è¯•å‰3ä¸ªbatch
                    break
                data, target = data.to(device), target.to(device)
                output = model(data)
                loss = F.nll_loss(output, target)
                losses.append(loss.item())

                pred = output.max(1, keepdim=True)[1]
                correct += pred.eq(target.view_as(pred)).sum().item()
                total += target.size(0)

        accuracy = correct / total if total > 0 else 0
        avg_loss = sum(losses) / len(losses) if losses else 0

        print(f"âœ… è¯„ä¼°å®Œæˆï¼ˆæµ‹è¯•æ ·æœ¬: {total}ï¼‰")
        print(f"   å‡†ç¡®ç‡: {accuracy * 100:.2f}%")
        print(f"   å¹³å‡æŸå¤±: {avg_loss:.4f}")

    except Exception as e:
        print(f"âš ï¸  è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        # ä¸è¿”å›Falseï¼Œå› ä¸ºè¿™ä¸æ˜¯è‡´å‘½é”™è¯¯

    # 7. å†…å­˜ä½¿ç”¨
    print(f"\n7ï¸âƒ£  å†…å­˜ä½¿ç”¨æƒ…å†µ...")
    if device.type == 'cuda':
        allocated = torch.cuda.memory_allocated(device) / 1024 / 1024
        reserved = torch.cuda.memory_reserved(device) / 1024 / 1024
        print(f"âœ… CUDAå†…å­˜")
        print(f"   å·²åˆ†é…: {allocated:.2f} MB")
        print(f"   å·²ä¿ç•™: {reserved:.2f} MB")
    else:
        print(f"âœ… CPUæ¨¡å¼ï¼Œæ— éœ€æ˜¾å­˜")

    # æ€»ç»“
    print(f"\n{'=' * 60}")
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨¡å‹å¯ä»¥è¿›è¡Œå¾®è°ƒè®­ç»ƒ")
    print(f"{'=' * 60}\n")

    return True


def main():
    parser = argparse.ArgumentParser(description='Test model loading and inference')
    parser.add_argument('--model-path', type=str, required=True, help='path to model file')
    parser.add_argument('--device', type=str, default='cuda', choices=['cuda', 'cpu'],
                        help='device to use')
    parser.add_argument('--dataset', type=str, default='../data', help='dataset directory')

    args = parser.parse_args()

    success = test_model(args.model_path, device=args.device)
    exit(0 if success else 1)


if __name__ == '__main__':
    main()
